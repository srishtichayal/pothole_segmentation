{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80b7d810",
   "metadata": {},
   "source": [
    "# DATA PREPARATION\n",
    "\n",
    "This notebook is dedicated to preparing the dataset for two key tasks:\n",
    "\n",
    "1. Training a YOLOv8 Model for Pothole Detection\n",
    "2. Fine-tuning the Segment Anything Model (SAM) for Pothole Segmentation\n",
    "\n",
    "For YOLOv8, the object detection model requires annotations in a specific format: bounding boxes normalized to the image size, saved in text files following the YOLO format (class x_center y_center width height). This notebook converts raw annotation data into this structure to enable seamless training with YOLOv8.\n",
    "\n",
    "For fine-tuning SAM, the model requires a different input format. Specifically:\n",
    "1. Bounding boxes in (x_min, y_min, x_max, y_max) format are used as prompts,\n",
    "2. Binary masks (segmenting the pothole regions) serve as ground truth labels.\n",
    "\n",
    "This notebook processes the raw dataset to generate and save both bounding box prompts and corresponding binary masks in the appropriate structure. These preprocessed inputs are then used to train SAM’s mask decoder while keeping the encoders frozen.\n",
    "\n",
    "In summary, this notebook handles all the format conversions and preprocessing necessary to make the dataset compatible with both the YOLOv8 and fine-tuned SAM pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a1fcdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42e22f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def convert_polygons_to_bboxes(label_dir, bbox_dir, class_id=0):\n",
    "    \"\"\"\n",
    "    Converts polygon labels in YOLO segmentation format to bounding boxes in YOLO detection format.\n",
    "    \n",
    "    Args:\n",
    "        label_dir (str): path to the folder containing original label .txt files (polygon format)\n",
    "        bbox_dir (str): path to the folder to save converted bbox .txt files (YOLO format)\n",
    "        class_id (int): class ID to use for all bounding boxes (default is 0 for pothole)\n",
    "    \"\"\"\n",
    "    os.makedirs(bbox_dir, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(label_dir):\n",
    "        if not filename.endswith('.txt'):\n",
    "            continue\n",
    "\n",
    "        label_path = os.path.join(label_dir, filename)\n",
    "        bbox_path = os.path.join(bbox_dir, filename)\n",
    "\n",
    "        with open(label_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        bbox_lines = []\n",
    "        for line in lines:\n",
    "            parts = list(map(float, line.strip().split()))\n",
    "            if len(parts) < 6:\n",
    "                continue  # skip if not enough coords to make a bbox\n",
    "            coords = parts[1:]  # skip class ID\n",
    "\n",
    "            x_coords = coords[0::2]\n",
    "            y_coords = coords[1::2]\n",
    "\n",
    "            x_min, x_max = min(x_coords), max(x_coords)\n",
    "            y_min, y_max = min(y_coords), max(y_coords)\n",
    "\n",
    "            x_center = (x_min + x_max) / 2\n",
    "            y_center = (y_min + y_max) / 2\n",
    "            width = x_max - x_min\n",
    "            height = y_max - y_min\n",
    "\n",
    "            bbox_lines.append(f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n",
    "\n",
    "        # Save converted bboxes\n",
    "        with open(bbox_path, 'w') as f:\n",
    "            f.write('\\n'.join(bbox_lines))\n",
    "\n",
    "    print(f\"✅ Converted all polygon labels from '{label_dir}' to YOLO bboxes in '{bbox_dir}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "819db502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Converted all polygon labels from 'C:/Users/srish/OneDrive/Desktop/Pothole_Segmentation_YOLOv8/train/labels' to YOLO bboxes in 'C:/Users/srish/OneDrive/Desktop/Pothole_Segmentation_YOLOv8/train/bbox'\n",
      "✅ Converted all polygon labels from 'C:/Users/srish/OneDrive/Desktop/Pothole_Segmentation_YOLOv8/valid/labels' to YOLO bboxes in 'C:/Users/srish/OneDrive/Desktop/Pothole_Segmentation_YOLOv8/valid/bbox'\n"
     ]
    }
   ],
   "source": [
    "# Convert for training set\n",
    "convert_polygons_to_bboxes(\n",
    "    label_dir= 'C:/Users/srish/OneDrive/Desktop/Pothole_Segmentation_YOLOv8/train/labels',\n",
    "    bbox_dir= 'C:/Users/srish/OneDrive/Desktop/Pothole_Segmentation_YOLOv8/train/bbox',\n",
    "    class_id=0  # pothole\n",
    ")\n",
    "\n",
    "# Convert for validation set\n",
    "convert_polygons_to_bboxes(\n",
    "    label_dir='C:/Users/srish/OneDrive/Desktop/Pothole_Segmentation_YOLOv8/valid/labels',\n",
    "    bbox_dir='C:/Users/srish/OneDrive/Desktop/Pothole_Segmentation_YOLOv8/valid/bbox',\n",
    "    class_id=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7d8c573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(img_path):\n",
    "    \"\"\"Loads an image from a path.\"\"\"\n",
    "    image = cv2.imread(img_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6be037d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_masks_and_bboxes(label_path, img_shape):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        label_path (str): path to .txt label file (with polygon coordinates)\n",
    "        img_shape (tuple): (H, W) of the image (for scaling normalized coords)\n",
    "\n",
    "    Returns:\n",
    "        masks (List[np.ndarray]): list of binary masks, each (H, W)\n",
    "        boxes (List[np.ndarray]): list of bounding boxes [x_min, y_min, x_max, y_max]\n",
    "    \"\"\"\n",
    "    h, w = img_shape\n",
    "    base_mask = np.zeros((h, w), dtype=np.uint8)\n",
    "\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            items = [float(x) for x in line.strip().split()]\n",
    "            coords = items[1:]  # skip class id\n",
    "            if len(coords) < 6:\n",
    "                continue\n",
    "\n",
    "            polygon = []\n",
    "            for i in range(0, len(coords), 2):\n",
    "                x = int(round(coords[i] * w))\n",
    "                y = int(round(coords[i+1] * h))\n",
    "                polygon.append((x, y))\n",
    "\n",
    "            cv2.fillPoly(base_mask, [np.array(polygon, dtype=np.int32)], 1)\n",
    "\n",
    "    # Now separate components in the filled mask\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(\n",
    "        base_mask, connectivity=8\n",
    "    )\n",
    "\n",
    "    masks = []\n",
    "    boxes = []\n",
    "\n",
    "    for i in range(1, num_labels):  # skip background\n",
    "        component_mask = (labels == i).astype(np.uint8)\n",
    "        masks.append(component_mask)\n",
    "\n",
    "        x, y, w_box, h_box, _ = stats[i]\n",
    "        boxes.append(np.array([x, y, x + w_box, y + h_box]))\n",
    "\n",
    "    return masks, boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eccdbe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = 'C:/Users/srish/OneDrive/Desktop/Pothole_Segmentation_YOLOv8/train/images'\n",
    "label_dir = 'C:/Users/srish/OneDrive/Desktop/Pothole_Segmentation_YOLOv8/train/labels'\n",
    "ground_truth_masks = {}\n",
    "bbox_coords = {}\n",
    "for file in os.listdir(image_dir):\n",
    "    img_path = os.path.join(image_dir, file)\n",
    "    k = os.path.splitext(file)[0]\n",
    "    label_path = os.path.join(label_dir, k + \".txt\")\n",
    "    img = read_image(img_path)\n",
    "    masks, boxes = extract_masks_and_bboxes(label_path, img.shape[:2])\n",
    "    masks = [(mask > 0).astype(np.uint8) for mask in masks]\n",
    "    ground_truth_masks[k] = masks\n",
    "    bbox_coords[k] = boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d4b8b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"C:/Users/srish/OneDrive/Desktop/Pothole_Segmentation_YOLOv8/train/\"\n",
    "with open(os.path.join(save_dir, \"ground_truth_masks.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(ground_truth_masks, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6716c734",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(save_dir, \"bbox_coords.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(bbox_coords, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "25635c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"C:/Users/srish/OneDrive/Desktop/Pothole_Segmentation_YOLOv8/train/ground_truth_masks.pkl\"\n",
    "\n",
    "# Load the dictionary\n",
    "with open(file_path, \"rb\") as f:\n",
    "    ground_truth_masks = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c758145c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "720"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ground_truth_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ced9980e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"C:/Users/srish/OneDrive/Desktop/Pothole_Segmentation_YOLOv8/train/bbox_coords.pkl\"\n",
    "\n",
    "# Load the dictionary\n",
    "with open(file_path, \"rb\") as f:\n",
    "    bbox_coords = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "85e91ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "720"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bbox_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ba73133b",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(bbox_coords.keys())\n",
    "k = keys[21]\n",
    "boxes = bbox_coords[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5168bb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box 0 shape: (4,), content: [158 348 442 445]\n"
     ]
    }
   ],
   "source": [
    "for i, box in enumerate(boxes):\n",
    "    print(f\"Box {i} shape: {box.shape}, content: {box}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "92161dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box 0 shape: (640, 640), content: [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "for i, mask in enumerate(ground_truth_masks[k]):\n",
    "    print(f\"Box {i} shape: {mask.shape}, content: {mask}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef36e43a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
